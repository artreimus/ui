chat:
  context: default
  greedy_mode: false
  logs_dir: data/chatlogs
  max_tokens: null
  model: models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf
  session: null
  vi_mode: false
  visible_overflow: true

general:
  log_level: INFO
  ram_limit: 48GB

generate:
  chunk_word_count: 1000
  model: models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf
  num_cpus: 16
  num_instructions: 100
  output_dir: generated
  prompt_file: prompt.txt
  seed_file: seed_tasks.json
  taxonomy_base: origin/main
  taxonomy_path: taxonomy

serve:
  gpu_layers: -1
  host_port: 0.0.0.0:8000
  max_ctx_size: 4096
  model_path: models/mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf
  num_cpus: 16
  ram_limit: 48GB
